<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>机器学习快速入门教程 on shesl-meow's note site</title><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</link><description>Recent content in 机器学习快速入门教程 on shesl-meow's note site</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/1.framing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/1.framing/</guid><description>问题构建 # 主要术语，全部。
标签 # 标签是我们要预测的事物，即简单线性回归中的 y 变量。
标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。
特征 # 特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征，按如下方式指定：$$x_1, x_2, &amp;hellip; x_n$$
样本 # 样本是指数据的特定实例：x。（我们采用粗体 x 表示它是一个矢量。）我们将样本分为以下两类：有标签样本、无标签样本
有标签样本同时包含特征和标签。即：
labeled examples: {features, label}: (x, y) 我们使用有标签样本来训练模型。在我们的垃圾邮件检测器示例中，有标签样本是用户明确标记为 “垃圾邮件” 或 “非垃圾邮件” 的各个电子邮件。
无标签样本包含特征，但不包含标签。即：
unlabeled examples: {features, ?}: (x, ?) 在使用有标签样本训练模型之后，我们会使用该模型预测无标签样本的标签。在垃圾邮件检测器示例中，无标签样本是用户尚未添加标签的新电子邮件。
模型 # 模型定义了特征与标签之间的关系。
模型生命周期的两个阶段：
训练是指创建或学习模型。也就是说，向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。 推断是指将训练后的模型应用于无标签样本。也就是说，使用经过训练的模型做出有用的预测 (y')。 回归与分类 # 回归模型可预测连续值。例如，回归模型做出的预测可回答如下问题：
加利福尼亚州一栋房产的价值是多少？ 用户点击此广告的概率是多少？ 分类模型可预测离散值。例如，分类模型做出的预测可回答如下问题：</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/10.regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/10.regularization/</guid><description>正则化 # 概述 # 降低复杂模型的复杂度来防止过拟合，这种原则称为正则化。
也就是说，并非只是以最小化损失（经验风险最小化）为目标：$$minimize(Loss(Data[Model]))$$
而是以最小化损失和复杂度为目标，这称为结构风险最小化：$$minimize(Loss(Data[Model]) + complexity(Model))$$
现在，我们的训练优化算法是一个由两项内容组成的函数：
一个是损失项，用于衡量模型与数据的拟合度； 另一个是正则化项，用于衡量模型复杂度。 机器学习速成课程重点介绍了两种衡量模型复杂度的常见方式（这两种方式有些相关）：
将模型复杂度作为模型中所有特征的权重的函数。 将模型复杂度作为具有非零权重的特征总数的函数。（后面的一个单元介绍了这种方法。） 如果模型复杂度是权重的函数，则特征权重的绝对值越高，对模型复杂度的贡献就越大。
L2 正则化 # 我们可以使用 L2 正则化 公式来量化复杂度，该公式将正则化项定义为所有特征权重的平方和：
$$L_2\ regularization\ term=||w||^2_2=w_1^2+w_2^2+&amp;hellip;+w_n^2$$
在这个公式中，接近于 0 的权重对模型复杂度几乎没有影响，而离群值权重则可能会产生巨大的影响。
简化正则化 lambda # 模型开发者通过以下方式来调整正则化项的整体影响：用正则化项的值乘以名为 lambda（又称为正则化率）的标量。也就是说，模型开发者会执行以下运算：
$$minimize(Loss(Data[Model]) + \lambda complexity(Model))$$
在选择 lambda 值时，目标是在简单化和训练数据拟合之间达到适当的平衡：
如果您的 lambda 值过高，则模型会非常简单，但是您将面临数据欠拟合的风险。您的模型将无法从训练数据中获得足够的信息来做出有用的预测。 如果您的 lambda 值过低，则模型会比较复杂，并且您将面临数据过拟合的风险。您的模型将因获得过多训练数据特点方面的信息而无法泛化到新数据。 注意：将 lambda 设为 0 可彻底取消正则化。 在这种情况下，训练的唯一目的将是最小化损失，而这样做会使过拟合的风险达到最高。
理想的 lambda 值生成的模型可以很好地泛化到以前未见过的新数据。 遗憾的是，理想的 lambda 值取决于数据，因此您需要手动或自动进行一些调整。
关键词 # 泛化曲线、L2 正则化、过拟合、正则化、结构风险最小化、早停法、lambda、正则化率</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/11.logisticregression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/11.logisticregression/</guid><description>逻辑回归 # 计算概率 # 许多问题需要将概率估算值作为输出。逻辑回归是一种极其高效的概率计算机制。
S 型函数：
一个值域恰好在 0 到 1 之间的函数，定义为：$$\displaystyle y = \frac{1}{1 + e^{-z}}$$ z 表示使用逻辑回归训练的模型的线性层的输出。
损失函数 # 线性回归的损失函数是平方损失。逻辑回归的损失函数是对数损失函数，定义如下：
$$\displaystyle Log Loss = \sum_{(x,y)\in D} -ylog(y&amp;rsquo;) - (1 - y)log(1 - y&amp;rsquo;)​$$
其中：
$$(x, y) \in D$$ 是包含很多有标签样本 (x,y) 的数据集。 “y”是有标签样本中的标签。由于这是逻辑回归，因此 “y” 的每个值必须是 0 或 1。 “y&amp;rsquo;”是对于特征集“x”的预测值（介于 0 和 1 之间）。 正则化 # 正则化在逻辑回归建模中极其重要。如果没有正则化，逻辑回归的渐近性会不断促使损失在高维度空间内达到 0。因此，大多数逻辑回归模型会使用以下两个策略之一来降低模型复杂性：
L2 正则化。 早停法，即，限制训练步数或学习速率。</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/12.classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/12.classification/</guid><description>分类 # 阈值 # 为了将逻辑回归值映射到二元类别，您必须指定分类阈值（也称为判定阈值）。
准确率 # 我们假设：
$$H_0$$ 成立 $$H_1$$ 成立 接收 不犯错（TP） 第 II 类错误（取伪错误 FP） 拒绝 第 I 类错误（弃真错误 FN） 不犯错（TN） 准确率是指我们的模型预测正确的结果所占的比例：
$$\displaystyle \text{Accuracy} = \frac{\text{Number of correct predictions}}{\text{Total number of predictions}}$$ 对于二元分类，也可以根据正类别和负类别按如下方式计算准确率：
$$\displaystyle \text{Accuracy} = \frac{TP+TN}{TP+TN+FP+FN}$$ 当您使用分类不平衡的数据集（比如正类别标签和负类别标签的数量之间存在明显差异）时，单单准确率一项并不能反映全面情况。
精确率和召回率 # 精确率的定义如下：$$\displaystyle \text{Precision} = \frac{TP}{TP+FP}$$
从数学上讲，召回率的定义如下：$$\displaystyle \text{召回率} = \frac{TP}{TP+FN}$$</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/2.descending/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/2.descending/</guid><description>深入了解机器学习 # 线性回归是一种找到最适合一组点的直线或超平面的方法。本模块会先直观介绍线性回归，为介绍线性回归的机器学习方法奠定基础。
线性回归 # 关键字词
偏差、 推断、线性回归、权重
训练与损失 # 概念 # 训练：
训练模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。
在监督式学习中，机器学习算法通过以下方式构建模型：
检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为经验风险最小化。 损失：
损失是对糟糕预测的惩罚。也就是说，损失是一个数值，表示对于单个样本而言模型预测的准确程度。 如果模型的预测完全准确，则损失为零，否则损失会较大。训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。 损失函数 # 平方损失：是一种常见的损失函数
接下来我们要看的线性回归模型使用的是一种称为平方损失（又称为 L2 损失）的损失函数。单个样本的平方损失如下：
= the square of the difference between the label and the prediction
= (observation - prediction(x))2
= (y - y&amp;#39;)2 均方误差 (MSE) 指的是每个样本的平均平方损失。要计算 MSE，请求出各个样本的所有平方损失之和，然后除以样本数量：
$$\displaystyle MSE = \frac{1}{N} \sum_{(x,y) \in D} (y - prediction(x))^2$$，其中：</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/3.reduceloss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/3.reduceloss/</guid><description>降低损失 # 迭代方法 # 下图显示了机器学习算法用于训练模型的迭代试错过程：
模型部分将一个或多个特征作为输入，然后返回一个预测 (y&amp;rsquo;) 作为输出。
计算损失部分是模型将要使用的损失函数。
计算参数更新部分：机器学习系统就是在此部分检查损失函数的值，并生成新参数值。机器学习系统将根据所有标签重新评估所有特征，为损失函数生成一个新值，而该值又产生新的参数值。
通常，可以不断迭代，直到总体损失不再变化或至少变化极其缓慢为止。这时候，我们可以说该模型已收敛。
关键字词：
收敛、损失、训练
梯度下降法 # 学习速率 # 梯度下降法算法用梯度乘以一个称为学习速率（有时也称为步长）的标量，以确定下一个点的位置。
如果您选择的学习速率过小，就会花费太长的学习时间； 相反，如果您指定的学习速率过大，下一个点将永远在 U 形曲线的底部随意弹跳； 每个回归问题都存在一个金发姑娘学习速率。“金发姑娘”值与损失函数的平坦程度相关。如果您知道损失函数的梯度较小，则可以放心地试着采用更大的学习速率，以补偿较小的梯度并获得更大的步长。 关键字词：
超参数、学习速率、步长
随机梯度下降 # 在梯度下降法中，批量指的是用于在单次迭代中计算梯度的样本总数。到目前为止，我们一直假定批量是指整个数据集。就 Google 的规模而言，数据集通常包含数十亿甚至数千亿个样本。此外，Google 数据集通常包含海量特征。因此，一个批量可能相当巨大。如果是超大批量，则单次迭代就可能要花费很长时间进行计算。
包含随机抽样样本的大型数据集可能包含冗余数据。实际上，批量大小越大，出现冗余的可能性就越高。一些冗余可能有助于消除杂乱的梯度，但超大批量所具备的预测价值往往并不比大型批量高。
如果我们可以通过更少的计算量得出正确的平均梯度，会怎么样？通过从我们的数据集中随机选择样本，我们可以通过小得多的数据集估算（尽管过程非常杂乱）出较大的平均值。 随机梯度下降法(SGD) 将这种想法运用到极致，它每次迭代只使用一个样本（批量大小为 1）。如果进行足够的迭代，SGD 也可以发挥作用，但过程会非常杂乱。“随机”这一术语表示构成各个批量的一个样本都是随机选择的。
小批量随机梯度下降法（小批量 SGD）是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 10-1000 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。
为了简化说明，我们只针对单个特征重点介绍了梯度下降法。请放心，梯度下降法也适用于包含多个特征的特征集。</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/4.tensorflowapi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/4.tensorflowapi/</guid><description>TensoFlow API # tf.estimator API # import tensorflow as tf # set up a linear classifier classifier = tf.estimator.LinearClassifier() # train the model on some example data classfier.train(input=train_input_fn, steps=2000) # use it to predict predictions = classifier.predict(input_fn = predict_input_fn)</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/5.generalization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/5.generalization/</guid><description>泛化 # 过拟合 # 下图所示的模型过拟合了训练数据的特性。过拟合模型在训练过程中产生的损失很低，但在预测新数据方面的表现却非常糟糕。如果某个模型在拟合当前样本方面表现良好，那么我们如何相信该模型会对新数据做出良好的预测呢？正如您稍后将看到的，过拟合是由于模型的复杂程度超出所需程度而造成的。机器学习的基本冲突是适当拟合我们的数据，但也要尽可能简单地拟合数据。
机器学习的目标是对从真实概率分布（已隐藏）中抽取的新数据做出良好预测。遗憾的是，模型无法查看整体情况；模型只能从训练数据集中取样。如果某个模型在拟合当前样本方面表现良好，那么您如何相信该模型也会对从未见过的样本做出良好预测呢？
奥卡姆的威廉是 14 世纪一位崇尚简单的修士和哲学家。他认为科学家应该优先采用更简单（而非更复杂）的公式或理论。奥卡姆剃刀定律在机器学习方面的运用如下：
机器学习模型越简单，良好的实证结果就越有可能不仅仅基于样本的特性。
现今，我们已将奥卡姆剃刀定律正式应用于统计学习理论和计算学习理论领域。这些领域已经形成了泛化边界，即统计化描述模型根据以下因素泛化到新数据的能力：
模型的复杂程度 模型在处理训练数据方面的表现 虽然理论分析在理想化假设下可提供正式保证，但在实践中却很难应用。机器学习速成课程则侧重于实证评估，以评判模型泛化到新数据的能力。
机器学习模型旨在根据以前未见过的新数据做出良好预测。但是，如果您要根据数据集构建模型，如何获得以前未见过的数据呢？一种方法是将您的数据集分成两个子集：
训练集 - 用于训练模型的子集。 测试集 - 用于测试模型的子集。 一般来说，在测试集上表现是否良好是衡量能否在新数据上表现良好的有用指标，前提是：
测试集足够大。 您不会反复使用相同的测试集来作假。 机器学习细则 # 以下三项基本假设阐明了泛化：
我们从分布中随机抽取独立同分布 (i.i.d) 的样本。换言之，样本之间不会互相影响。（另一种解释：i.i.d. 是表示变量随机性的一种方式）。 分布是平稳的；即分布在数据集内不会发生变化。 我们从同一分布的数据划分中抽取样本。 在实践中，我们有时会违背这些假设。例如：
想象有一个选择要展示的广告的模型。如果该模型在某种程度上根据用户以前看过的广告选择广告，则会违背 i.i.d. 假设。 想象有一个包含一年零售信息的数据集。用户的购买行为会出现季节性变化，这会违反平稳性。 如果违背了上述三项基本假设中的任何一项，那么我们就必须密切注意指标。
关键字词 # 泛化、过拟合、预测、 平稳性、测试集、训练集</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/6.trainingandtest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/6.trainingandtest/</guid><description>测试集和数据集 # 上一单元介绍了将数据集分为两个子集的概念：
训练集 - 用于训练模型的子集。 测试集 - 用于测试训练后模型的子集。 您可以想象按如下方式拆分单个数据集：</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/7.validation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/7.validation/</guid><description>验证集 # 上一单元介绍了如何将数据集划分为训练集和测试集。借助这种划分，您可以对一个样本集进行训练，然后使用不同的样本集测试模型。采用两种分类之后，工作流程可能如下所示：
将数据集划分为两个子集是个不错的想法，但不是万能良方。通过将数据集划分为三个子集（如下图所示），您可以大幅降低过拟合的发生几率：
使用验证集评估训练集的效果。然后，在模型“通过”验证集之后，使用测试集再次检查评估结果。下图展示了这一新工作流程：
在这一经过改进的工作流程中：
选择在验证集上获得最佳效果的模型。 使用测试集再次检查该模型。 该工作流程之所以更好，原因在于它暴露给测试集的信息更少。</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/8.representation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/8.representation/</guid><description>特征工程 # 将原始数据映射到特征 # 下图左侧表示来自输入数据源的原始数据，右侧表示特征矢量，也就是组成数据集中样本的浮点值集。 特征工程指的是将原始数据转换为特征矢量。进行特征工程预计需要大量时间。
许多机器学习模型都必须将特征表示为实数向量，因为特征值必须与模型权重相乘。
数据表示 # 映射数值：
整数和浮点数据不需要特殊编码，因为它们可以与数字权重相乘。 映射分类值：
分类特征具有一组离散的可能值。
由于模型不能将字符串与学习到的权重相乘，因此我们使用特征工程将字符串转换为数字值：
要实现这一点，我们可以定义一个从特征值（我们将其称为可能值的词汇表）到整数的映射。世界上的每条街道并非都会出现在我们的数据集中，因此我们可以将所有其他街道分组为一个全部包罗的“其他”类别，称为 OOV（词汇表外）分桶。
这种编码存在不能设置权重、不能同时表示多个等限制。
要去除这些限制，我们可以为模型中的每个分类特征创建一个二元向量来表示这些值，如下所述：
对于适用于样本的值，将相应向量元素设为 1。 将所有其他元素设为 0。 该向量的长度等于词汇表中的元素数。当只有一个值为 1 时，这种表示法称为独热编码；当有多个值为 1 时，这种表示法称为多热编码。例子如下图：
稀疏表示法 # 假设数据集中有 100 万个不同的街道名称，您希望将其包含为 street_name 的值。如果直接创建一个包含 100 万个元素的二元向量，其中只有 1 或 2 个元素为 ture，则是一种非常低效的表示法，在处理这些向量时会占用大量的存储空间并耗费很长的计算时间。在这种情况下，一种常用的方法是使用稀疏表示法，其中仅存储非零值。在稀疏表示法中，仍然为每个特征值学习独立的模型权重，如上所述。
关键词 # 离散特征、特征工程、独热编码、表示
良好的特征工程 # 1. 避免很少使用的离散特征值： # 良好的特征值应该在数据集中出现大约 5 次以上。</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/9.featurecrosses/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/9.featurecrosses/</guid><description>特征组合 # 对非线性规律进行组合 # 特征组合是指通过将两个或多个输入特征相乘来对特征空间中的非线性规律进行编码的合成特征。“cross”（组合）这一术语来自 cross product（向量积）。
我们通过将 $$x_1$$ 与 $$x_2$$ 组合来创建一个名为 $$x_3$$ 的特征组合：$$x_3 = x_1 x_2$$
我们像处理其他特征一样来处理这个新建的 $$x_3$$ 特征组合。线性公式变为：$$y = b + w_1x_1 + w_2x_2 + w_3x_3$$
线性算法可以算出 $$w_3$$ 的权重，就像算出 $$w_1$$ 和 $$w_2$$ 的权重一样。换言之，虽然 $$w_3$$ 表示非线性信息，但您不需要改变线性模型的训练方式来确定 $$w_3$$ 的值。
我们可以创建很多不同种类的特征组合。例如：
[A X B]：将两个特征的值相乘形成的特征组合； [A X B X C X D X E]：将五个特征值相乘形成的特征组合； [A X A]：对单个特征的值求平方形成的特征组合。 关键字词：特征组合、合成特征
组合独热矢量 # 笛卡儿积</description></item><item><title/><link>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/rnn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shesl-meow.github.io/docs/%E7%AE%97%E6%B3%95%E7%BB%9F%E8%AE%A1/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/rnn/</guid><description>学习地址：
https://www.youtube.com/watch?v=lWkFhVq9-nc introduction to RNN # Feed Forward Neural Network, FFNN # In a Feed-Forward Network, information flow only in forward direction.
graph LR;
I{input}; IL(Input Layer); HL(Hidden Layer); OL(Output Layer); O{Predicted output}
I--&amp;gt;IL; IL--&amp;gt;HL; HL--&amp;gt;OL; OL--&amp;gt;O; Decisions are based on current input. No memory about the past. No future scope. Question:
cannot handle sequential data. considers only the current input. cannot memorize previous inputs.</description></item></channel></rss>