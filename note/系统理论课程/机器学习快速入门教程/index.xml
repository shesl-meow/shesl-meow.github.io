<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>机器学习快速入门教程 on shesl's blog</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</link><description>Recent content in 机器学习快速入门教程 on shesl's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>shesl-meow@qq.com (佘崧林)</managingEditor><webMaster>shesl-meow@qq.com (佘崧林)</webMaster><lastBuildDate>Tue, 30 Jul 2019 11:01:03 +0800</lastBuildDate><atom:link href="http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>introduction to `RNN`</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/rnn/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/rnn/</guid><description>学习地址： https://www.youtube.com/watch?v=lWkFhVq9-nc Feed Forward Neural Network, FFNN In a Feed-Forward Network, information flow only in forward direction. 1 2 3 4 5 graph LR; I{input}; IL(Input Layer); HL(Hidden Layer); OL(Output Layer); O{Predicted output} I--&amp;gt;IL; IL--&amp;gt;HL; HL--&amp;gt;OL; OL--&amp;gt;O; Decisions are based on current input. No memory about the past. No future scope. Question: cannot handle sequential data. considers only the current input. cannot memorize previous inputs. Recurrent</description></item><item><title>TensoFlow API</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/4.tensorflowapi/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/4.tensorflowapi/</guid><description>tf.estimator API 1 2 3 4 5 6 7 8 9 10 import tensorflow as tf # set up a linear classifier classifier = tf.estimator.LinearClassifier() # train the model on some example data classfier.train(input=train_input_fn, steps=2000) # use it to predict predictions = classifier.predict(input_fn = predict_input_fn)</description></item><item><title>测试集和数据集</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/6.trainingandtest/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/6.trainingandtest/</guid><description>上一单元介绍了将数据集分为两个子集的概念： 训练集 - 用于训练模型的子集。 测试集 - 用于测试训练后模型的子集。 您可以想象按如下方式拆分单个数据集：</description></item><item><title>泛化</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/5.generalization/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/5.generalization/</guid><description>过拟合 下图所示的模型过拟合了训练数据的特性。过拟合模型在训练过程中产生的损失很低，但在预测新数据方面的表现却非常糟糕。如果某个模型在拟合当前</description></item><item><title>分类</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/12.classification/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/12.classification/</guid><description>阈值 为了将逻辑回归值映射到二元类别，您必须指定分类阈值（也称为判定阈值）。 准确率 我们假设： $$H_0$$ 成立 $$H_1$$ 成立 接收 不犯错（TP） 第 II 类错误（取伪错误</description></item><item><title>降低损失</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/3.reduceloss/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/3.reduceloss/</guid><description>迭代方法 下图显示了机器学习算法用于训练模型的迭代试错过程： 模型部分将一个或多个特征作为输入，然后返回一个预测 (y&amp;rsquo;) 作为输出。 计算损失部分是模型将</description></item><item><title>逻辑回归</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/11.logisticregression/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/11.logisticregression/</guid><description>计算概率 许多问题需要将概率估算值作为输出。逻辑回归是一种极其高效的概率计算机制。 S 型函数： 一个值域恰好在 0 到 1 之间的函数，定义为：$$\di</description></item><item><title>深入了解机器学习</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/2.descending/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/2.descending/</guid><description>线性回归是一种找到最适合一组点的直线或超平面的方法。本模块会先直观介绍线性回归，为介绍线性回归的机器学习方法奠定基础。 线性回归 关键字词 偏差、</description></item><item><title>特征工程</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/8.representation/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/8.representation/</guid><description>将原始数据映射到特征 下图左侧表示来自输入数据源的原始数据，右侧表示特征矢量，也就是组成数据集中样本的浮点值集。 特征工程指的是将原始数据转换为</description></item><item><title>特征组合</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/9.featurecrosses/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/9.featurecrosses/</guid><description>对非线性规律进行组合 特征组合是指通过将两个或多个输入特征相乘来对特征空间中的非线性规律进行编码的合成特征。“cross”（组合）这一术语来自</description></item><item><title>问题构建</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/1.framing/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/1.framing/</guid><description>主要术语，全部。 标签 标签是我们要预测的事物，即简单线性回归中的 y 变量。 标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事</description></item><item><title>验证集</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/7.validation/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/7.validation/</guid><description>上一单元介绍了如何将数据集划分为训练集和测试集。借助这种划分，您可以对一个样本集进行训练，然后使用不同的样本集测试模型。采用两种分类之后，工</description></item><item><title>正则化</title><link>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/10.regularization/</link><pubDate>Tue, 30 Jul 2019 11:01:03 +0800</pubDate><author>shesl-meow@qq.com (佘崧林)</author><guid>http://shesl-meow.github.io/note/%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/10.regularization/</guid><description>概述 降低复杂模型的复杂度来防止过拟合，这种原则称为正则化。 也就是说，并非只是以最小化损失（经验风险最小化）为目标：$$minimize(Lo</description></item></channel></rss>